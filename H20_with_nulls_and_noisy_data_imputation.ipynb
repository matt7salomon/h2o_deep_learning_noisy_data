{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas \n",
    "# %pip install tensorflow\n",
    "# %pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/py310/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/py310/lib/python3.10/site-packages (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/py310/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/py310/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/py310/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/py310/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/envs/py310/lib/python3.10/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/py310/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/py310/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/py310/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs in training data: 22911\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic data\n",
    "n_samples = 1000\n",
    "n_features = 286\n",
    "\n",
    "# Features with some correlation to the target\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "# Introduce NaNs in some features (random 10% missing values)\n",
    "\n",
    "\n",
    "# Generate target variable with correlation to the first few features\n",
    "# Adding noise for realistic correlation\n",
    "y = 5 * X[:, 0] + 2 * X[:, 1] - 3 * X[:, 2] + np.random.randn(n_samples) * 0.5\n",
    "nan_mask = np.random.rand(n_samples, n_features) < 0.1\n",
    "X[nan_mask] = np.nan\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert X_train and X_test to Pandas DataFrames to simulate your setup\n",
    "train_x = pd.DataFrame(X_train)\n",
    "test_x = pd.DataFrame(X_test)\n",
    "\n",
    "train_y = y_train\n",
    "test_y = y_test\n",
    "\n",
    "# Verify the number of NaN values\n",
    "print(\"Number of NaNs in training data:\", np.isnan(train_x).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 16.7323\n",
      "Epoch [20/100], Loss: 11.7542\n",
      "Epoch [30/100], Loss: 4.3444\n",
      "Epoch [40/100], Loss: 8.4156\n",
      "Epoch [50/100], Loss: 6.1261\n",
      "Epoch [60/100], Loss: 10.6054\n",
      "Epoch [70/100], Loss: 3.2802\n",
      "Epoch [80/100], Loss: 3.2385\n",
      "Epoch [90/100], Loss: 3.4161\n",
      "Epoch [100/100], Loss: 6.7244\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create synthetic data\n",
    "np.random.seed(42)\n",
    "num_samples = 10000\n",
    "num_features = 286\n",
    "\n",
    "# Generate random data for train_x (normally distributed)\n",
    "train_x = np.random.randn(num_samples, num_features)\n",
    "\n",
    "# Generate weights for each feature to introduce correlation between train_x and train_y\n",
    "weights = np.random.randn(num_features)\n",
    "\n",
    "# Generate train_y as a linear combination of train_x with some random noise\n",
    "train_y = np.dot(train_x, weights) + np.random.randn(num_samples) * 0.5  # Adding noise\n",
    "\n",
    "# Introduce NaNs into the dataset\n",
    "train_x[::10] = np.nan  # Every 10th row will have NaN values\n",
    "\n",
    "# Convert to pandas DataFrames for consistency with the original code\n",
    "train_x = pd.DataFrame(train_x, columns=[f'feature_{i}' for i in range(num_features)])\n",
    "train_y = pd.DataFrame(train_y, columns=['target'])\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(train_x.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(train_y.values, dtype=torch.float32).squeeze()\n",
    "\n",
    "# Replace NaNs with 0 for the forward passx\n",
    "X_tensor = torch.nan_to_num(X_tensor, nan=0.0)\n",
    "\n",
    "# Define the model\n",
    "class CustomRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(CustomRegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "model = CustomRegressionModel(input_dim=num_features)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i in range(0, X_tensor.size(0), batch_size):\n",
    "        batch_X = X_tensor[i:i+batch_size]\n",
    "        batch_y = y_tensor[i:i+batch_size]\n",
    "       \n",
    "        # Forward pass\n",
    "        predictions = model(batch_X)\n",
    "        loss = criterion(predictions.squeeze(), batch_y)\n",
    "       \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "   \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'h2o'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh2o\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mh2o\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m H2ODeepLearningEstimator, H2OAutoML\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'h2o'"
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.estimators import H2ODeepLearningEstimator, H2OAutoML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize H2O cluster\n",
    "h2o.init()\n",
    "\n",
    "# Create synthetic data\n",
    "np.random.seed(42)\n",
    "num_samples = 10000\n",
    "num_features = 286\n",
    "\n",
    "# Generate random data for train_x (normally distributed)\n",
    "train_x = np.random.randn(num_samples, num_features)\n",
    "\n",
    "# Generate weights for each feature to introduce correlation between train_x and train_y\n",
    "weights = np.random.randn(num_features)\n",
    "\n",
    "# Generate train_y as a linear combination of train_x with some random noise\n",
    "train_y = np.dot(train_x, weights) + np.random.randn(num_samples) * 0.5  # Adding noise\n",
    "\n",
    "# Introduce NaNs into the dataset\n",
    "train_x[::10] = np.nan  # Every 10th row will have NaN values\n",
    "\n",
    "# Convert to pandas DataFrames for consistency\n",
    "train_x = pd.DataFrame(train_x, columns=[f'feature_{i}' for i in range(num_features)])\n",
    "train_y = pd.DataFrame(train_y, columns=['target'])\n",
    "\n",
    "# Convert the pandas DataFrame to an H2OFrame\n",
    "train_x_h2o = h2o.H2OFrame(train_x)\n",
    "train_y_h2o = h2o.H2OFrame(train_y)\n",
    "\n",
    "# Combine train_x and train_y for H2O training\n",
    "train_h2o = train_x_h2o.cbind(train_y_h2o)\n",
    "\n",
    "# Define features and target columns\n",
    "features = train_x_h2o.columns\n",
    "target = 'target'\n",
    "\n",
    "# Initialize and train H2O Deep Learning model\n",
    "model = H2ODeepLearningEstimator(\n",
    "    hidden=[256, 128, 64],\n",
    "    epochs=100,\n",
    "    activation=\"RectifierWithDropout\",\n",
    "    input_dropout_ratio=0.2,\n",
    "    hidden_dropout_ratios=[0.3, 0.3, 0.3],\n",
    "    l1=1e-5,\n",
    "    l2=1e-5\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.train(x=features, y=target, training_frame=train_h2o)\n",
    "\n",
    "# Print the model performance\n",
    "performance = model.model_performance()\n",
    "print(performance)\n",
    "\n",
    "# Alternatively, you could use AutoML to search for the best model\n",
    "# aml = H2OAutoML(max_runtime_secs=600, project_name=\"regression\")\n",
    "# aml.train(x=features, y=target, training_frame=train_h2o)\n",
    "\n",
    "# performance = aml.leader.model_performance()\n",
    "# print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>9 hours 23 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/Los_Angeles</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.5</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>25 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>mattsalomon</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>2.997 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>10</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>10</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.15 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         9 hours 23 mins\n",
       "H2O_cluster_timezone:       America/Los_Angeles\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.5\n",
       "H2O_cluster_version_age:    25 days\n",
       "H2O_cluster_name:           mattsalomon\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    2.997 Gb\n",
       "H2O_cluster_total_cores:    10\n",
       "H2O_cluster_allowed_cores:  10\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.15 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "ModelMetricsRegression: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 55.29712009566408\n",
      "RMSE: 7.43620333877874\n",
      "MAE: 5.450701462911353\n",
      "RMSLE: NaN\n",
      "Mean Residual Deviance: 55.29712009566408\n"
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.estimators import H2ODeepLearningEstimator#, H2OAutoML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize H2O cluster\n",
    "h2o.init()\n",
    "\n",
    "# Create synthetic data\n",
    "np.random.seed(42)\n",
    "num_samples = 10000\n",
    "num_features = 286\n",
    "\n",
    "# Generate random data for train_x (normally distributed)\n",
    "train_x = np.random.randn(num_samples, num_features)\n",
    "\n",
    "# Generate weights for each feature to introduce correlation between train_x and train_y\n",
    "weights = np.random.randn(num_features)\n",
    "\n",
    "# Generate train_y as a linear combination of train_x with some random noise\n",
    "train_y = np.dot(train_x, weights) + np.random.randn(num_samples) * 0.5  # Adding noise\n",
    "\n",
    "# Introduce NaNs into the dataset\n",
    "train_x[::10] = np.nan  # Every 10th row will have NaN values\n",
    "\n",
    "# Convert to pandas DataFrames for consistency\n",
    "train_x = pd.DataFrame(train_x, columns=[f'feature_{i}' for i in range(num_features)])\n",
    "train_y = pd.DataFrame(train_y, columns=['target'])\n",
    "\n",
    "# Convert the pandas DataFrame to an H2OFrame\n",
    "train_x_h2o = h2o.H2OFrame(train_x)\n",
    "train_y_h2o = h2o.H2OFrame(train_y)\n",
    "\n",
    "# Combine train_x and train_y for H2O training\n",
    "train_h2o = train_x_h2o.cbind(train_y_h2o)\n",
    "\n",
    "# Define features and target columns\n",
    "features = train_x_h2o.columns\n",
    "target = 'target'\n",
    "\n",
    "# Initialize and train H2O Deep Learning model\n",
    "model = H2ODeepLearningEstimator(\n",
    "    hidden=[256, 128, 64],\n",
    "    epochs=100,\n",
    "    activation=\"RectifierWithDropout\",\n",
    "    input_dropout_ratio=0.2,\n",
    "    hidden_dropout_ratios=[0.3, 0.3, 0.3],\n",
    "    l1=1e-5,\n",
    "    l2=1e-5\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.train(x=features, y=target, training_frame=train_h2o)\n",
    "\n",
    "# Print the model performance\n",
    "performance = model.model_performance()\n",
    "print(performance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "test_x = np.random.randn(num_samples, num_features)\n",
    "test_y = np.dot(test_x, weights) + np.random.randn(num_samples) * 0.5  # Adding noise\n",
    "test_x[::10] = np.nan\n",
    "test_x_h2o = h2o.H2OFrame(test_x, column_names=[f'feature_{i}' for i in range(num_features)])\n",
    "test_y_h2o = h2o.H2OFrame(test_y,column_names=['target'])\n",
    "\n",
    "# Combine train_x and train_y for H2O training\n",
    "test_h2o = test_x_h2o.cbind(test_y_h2o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 286), (10000, 286))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "train_pred = model.predict(train_h2o)\n",
    "test_pred = model.predict(test_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py310/lib/python3.10/site-packages/h2o/frame.py:1981: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred_train</th>\n",
       "      <th>y_true_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.143833</td>\n",
       "      <td>-15.076742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.036379</td>\n",
       "      <td>8.620448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.299648</td>\n",
       "      <td>28.172118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.547597</td>\n",
       "      <td>34.670782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.279449</td>\n",
       "      <td>-4.697201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>-15.412716</td>\n",
       "      <td>-20.868444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>-9.777033</td>\n",
       "      <td>-13.297913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>-27.374835</td>\n",
       "      <td>-33.682206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>5.994463</td>\n",
       "      <td>12.164308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>4.631997</td>\n",
       "      <td>8.064832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_pred_train  y_true_train\n",
       "0        -2.143833    -15.076742\n",
       "1         3.036379      8.620448\n",
       "2        19.299648     28.172118\n",
       "3        26.547597     34.670782\n",
       "4        -3.279449     -4.697201\n",
       "...            ...           ...\n",
       "9995    -15.412716    -20.868444\n",
       "9996     -9.777033    -13.297913\n",
       "9997    -27.374835    -33.682206\n",
       "9998      5.994463     12.164308\n",
       "9999      4.631997      8.064832\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data={'y_pred_train':train_pred.as_data_frame().values.flatten(), 'y_true_train':train_y.values.flatten()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make predictions\n",
    "# test_h2o = h2o.H2OFrame(test_x)\n",
    "# predictions = model.predict(test_h2o)\n",
    "\n",
    "# # View the predictions\n",
    "# print(predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |\n",
      "06:12:21.856: New models will be added to existing leaderboard regression@@target (leaderboard frame=null) with already 22 models.\n",
      "\n",
      "████████████████████████████████████████████████████\n",
      "06:20:35.12: StackedEnsemble_BestOfFamily_4_AutoML_2_20240924_61221 [StackedEnsemble best_of_family_1 (built with AUTO metalearner, using top model from each algorithm type)] failed: water.exceptions.H2OIllegalArgumentException: Failed to find the xval predictions frame. . .  Looks like keep_cross_validation_predictions wasn't set when building the models, or the frame was deleted.\n",
      "\n",
      "████████\n",
      "06:21:54.936: StackedEnsemble_BestOfFamily_5_AutoML_2_20240924_61221 [StackedEnsemble best_of_family_2 (built with AUTO metalearner, using top model from each algorithm type)] failed: water.exceptions.H2OIllegalArgumentException: Failed to find the xval predictions frame. . .  Looks like keep_cross_validation_predictions wasn't set when building the models, or the frame was deleted.\n",
      "06:21:54.959: StackedEnsemble_AllModels_4_AutoML_2_20240924_61221 [StackedEnsemble all_2 (built with AUTO metalearner, using all AutoML models)] failed: water.exceptions.H2OIllegalArgumentException: Failed to find the xval predictions frame. . .  Looks like keep_cross_validation_predictions wasn't set when building the models, or the frame was deleted.\n",
      "\n",
      "██\n",
      "06:22:15.296: StackedEnsemble_BestOfFamily_6_AutoML_2_20240924_61221 [StackedEnsemble best_of_family_3 (built with AUTO metalearner, using top model from each algorithm type)] failed: water.exceptions.H2OIllegalArgumentException: Failed to find the xval predictions frame. . .  Looks like keep_cross_validation_predictions wasn't set when building the models, or the frame was deleted.\n",
      "06:22:15.323: StackedEnsemble_AllModels_5_AutoML_2_20240924_61221 [StackedEnsemble all_3 (built with AUTO metalearner, using all AutoML models)] failed: water.exceptions.H2OIllegalArgumentException: Failed to find the xval predictions frame. . .  Looks like keep_cross_validation_predictions wasn't set when building the models, or the frame was deleted.\n",
      "\n",
      "█| (done) 100%\n",
      "ModelMetricsRegressionGLM: glm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 28.00739141134721\n",
      "RMSE: 5.292200998766695\n",
      "MAE: 1.6973435567053836\n",
      "RMSLE: NaN\n",
      "Mean Residual Deviance: 28.00739141134721\n",
      "R^2: 0.8983448524443512\n",
      "Null degrees of freedom: 9999\n",
      "Residual degrees of freedom: 9713\n",
      "Null deviance: 2755137.549332193\n",
      "Residual deviance: 280073.9141134721\n",
      "AIC: 62279.45520724916\n"
     ]
    }
   ],
   "source": [
    "from h2o.automl import H2OAutoML\n",
    "# Alternatively, you could use AutoML to search for the best model\n",
    "aml = H2OAutoML(max_runtime_secs=600, project_name=\"regression\")\n",
    "aml.train(x=features, y=target, training_frame=train_h2o)\n",
    "\n",
    "performance = aml.leader.model_performance()\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th>model_id                                               </th><th style=\"text-align: right;\">   rmse</th><th style=\"text-align: right;\">    mse</th><th style=\"text-align: right;\">    mae</th><th style=\"text-align: right;\">  rmsle</th><th style=\"text-align: right;\">  mean_residual_deviance</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>GLM_2_AutoML_2_20240924_61221                          </td><td style=\"text-align: right;\">5.29464</td><td style=\"text-align: right;\">28.0332</td><td style=\"text-align: right;\">1.71254</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">                 28.0332</td></tr>\n",
       "<tr><td>GLM_1_AutoML_1_20240923_211230                         </td><td style=\"text-align: right;\">5.29464</td><td style=\"text-align: right;\">28.0332</td><td style=\"text-align: right;\">1.71254</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">                 28.0332</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_2_AutoML_1_20240923_211230   </td><td style=\"text-align: right;\">5.29509</td><td style=\"text-align: right;\">28.038 </td><td style=\"text-align: right;\">1.71367</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">                 28.038 </td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_1_AutoML_1_20240923_211230</td><td style=\"text-align: right;\">5.29512</td><td style=\"text-align: right;\">28.0383</td><td style=\"text-align: right;\">1.71415</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">                 28.0383</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_2_AutoML_1_20240923_211230</td><td style=\"text-align: right;\">5.29513</td><td style=\"text-align: right;\">28.0384</td><td style=\"text-align: right;\">1.71412</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">                 28.0384</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_1_AutoML_1_20240923_211230   </td><td style=\"text-align: right;\">5.29523</td><td style=\"text-align: right;\">28.0395</td><td style=\"text-align: right;\">1.71372</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">                 28.0395</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_3_AutoML_1_20240923_211230   </td><td style=\"text-align: right;\">5.29554</td><td style=\"text-align: right;\">28.0428</td><td style=\"text-align: right;\">1.71425</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">                 28.0428</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_3_AutoML_1_20240923_211230</td><td style=\"text-align: right;\">5.29639</td><td style=\"text-align: right;\">28.0518</td><td style=\"text-align: right;\">1.71507</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">                 28.0518</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_1_20240923_211230                </td><td style=\"text-align: right;\">5.47443</td><td style=\"text-align: right;\">29.9694</td><td style=\"text-align: right;\">2.44844</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">                 29.9694</td></tr>\n",
       "<tr><td>DeepLearning_2_AutoML_2_20240924_61221                 </td><td style=\"text-align: right;\">5.61972</td><td style=\"text-align: right;\">31.5813</td><td style=\"text-align: right;\">2.68302</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">                 31.5813</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[36 rows x 6 columns]</pre>"
      ],
      "text/plain": [
       "model_id                                                    rmse      mse      mae    rmsle    mean_residual_deviance\n",
       "-------------------------------------------------------  -------  -------  -------  -------  ------------------------\n",
       "GLM_2_AutoML_2_20240924_61221                            5.29464  28.0332  1.71254      nan                   28.0332\n",
       "GLM_1_AutoML_1_20240923_211230                           5.29464  28.0332  1.71254      nan                   28.0332\n",
       "StackedEnsemble_AllModels_2_AutoML_1_20240923_211230     5.29509  28.038   1.71367      nan                   28.038\n",
       "StackedEnsemble_BestOfFamily_1_AutoML_1_20240923_211230  5.29512  28.0383  1.71415      nan                   28.0383\n",
       "StackedEnsemble_BestOfFamily_2_AutoML_1_20240923_211230  5.29513  28.0384  1.71412      nan                   28.0384\n",
       "StackedEnsemble_AllModels_1_AutoML_1_20240923_211230     5.29523  28.0395  1.71372      nan                   28.0395\n",
       "StackedEnsemble_AllModels_3_AutoML_1_20240923_211230     5.29554  28.0428  1.71425      nan                   28.0428\n",
       "StackedEnsemble_BestOfFamily_3_AutoML_1_20240923_211230  5.29639  28.0518  1.71507      nan                   28.0518\n",
       "DeepLearning_1_AutoML_1_20240923_211230                  5.47443  29.9694  2.44844      nan                   29.9694\n",
       "DeepLearning_2_AutoML_2_20240924_61221                   5.61972  31.5813  2.68302      nan                   31.5813\n",
       "[36 rows x 6 columns]\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = aml.leader.model_performance(test_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.584443849267315, 1.7659740471731105, 0.8880637559540919)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf.rmse(), perf.mae(), perf.r2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "train_pred = aml.predict(train_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py310/lib/python3.10/site-packages/h2o/frame.py:1981: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred_train</th>\n",
       "      <th>y_true_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.068778</td>\n",
       "      <td>0.068778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.727700</td>\n",
       "      <td>16.599437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-63.873488</td>\n",
       "      <td>-64.967615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-9.638754</td>\n",
       "      <td>-11.136724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.068778</td>\n",
       "      <td>0.373693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.699891</td>\n",
       "      <td>11.108575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>66.888468</td>\n",
       "      <td>67.440638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y_pred_train  y_true_train\n",
       "count  10000.000000  10000.000000\n",
       "mean       0.068778      0.068778\n",
       "std       15.727700     16.599437\n",
       "min      -63.873488    -64.967615\n",
       "25%       -9.638754    -11.136724\n",
       "50%        0.068778      0.373693\n",
       "75%        9.699891     11.108575\n",
       "max       66.888468     67.440638"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data={'y_pred_train':train_pred.as_data_frame().values.flatten(), 'y_true_train':train_y.values.flatten()}).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "test_pred = aml.predict(test_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py310/lib/python3.10/site-packages/h2o/frame.py:1981: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred_test</th>\n",
       "      <th>y_true_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.140927</td>\n",
       "      <td>-0.098234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.734737</td>\n",
       "      <td>16.692304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-58.230433</td>\n",
       "      <td>-58.609892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-10.167124</td>\n",
       "      <td>-11.406969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.068778</td>\n",
       "      <td>-0.272202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.628301</td>\n",
       "      <td>11.239609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>65.862511</td>\n",
       "      <td>64.911269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        y_pred_test   y_true_test\n",
       "count  10000.000000  10000.000000\n",
       "mean      -0.140927     -0.098234\n",
       "std       15.734737     16.692304\n",
       "min      -58.230433    -58.609892\n",
       "25%      -10.167124    -11.406969\n",
       "50%        0.068778     -0.272202\n",
       "75%        9.628301     11.239609\n",
       "max       65.862511     64.911269"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data={'y_pred_test':test_pred.as_data_frame().values.flatten(), 'y_true_test':test_y}).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLM Model: summary\n",
      "    family    link      regularization               lambda_search                                                                  number_of_predictors_total    number_of_active_predictors    number_of_iterations    training_frame\n",
      "--  --------  --------  ---------------------------  -----------------------------------------------------------------------------  ----------------------------  -----------------------------  ----------------------  ----------------------------------------------\n",
      "    gaussian  identity  Ridge ( lambda = 3.046E-4 )  nlambda = 30, lambda.max = 304.64, lambda.min = 3.046E-4, lambda.1se = 0.2401  286                           286                            30                      AutoML_2_20240924_61221_training_py_1_sid_a662\n"
     ]
    }
   ],
   "source": [
    "print(aml.leader.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th>model_id                                               </th><th style=\"text-align: right;\">   rmse</th><th style=\"text-align: right;\">    mse</th><th style=\"text-align: right;\">    mae</th><th style=\"text-align: right;\">  rmsle</th><th style=\"text-align: right;\">  mean_residual_deviance</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>GLM_2_AutoML_2_20240924_61221                          </td><td style=\"text-align: right;\">5.29464</td><td style=\"text-align: right;\">28.0332</td><td style=\"text-align: right;\">1.71254</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">                 28.0332</td></tr>\n",
       "<tr><td>GLM_1_AutoML_1_20240923_211230                         </td><td style=\"text-align: right;\">5.29464</td><td style=\"text-align: right;\">28.0332</td><td style=\"text-align: right;\">1.71254</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">                 28.0332</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_2_AutoML_1_20240923_211230   </td><td style=\"text-align: right;\">5.29509</td><td style=\"text-align: right;\">28.038 </td><td style=\"text-align: right;\">1.71367</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">                 28.038 </td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_1_AutoML_1_20240923_211230</td><td style=\"text-align: right;\">5.29512</td><td style=\"text-align: right;\">28.0383</td><td style=\"text-align: right;\">1.71415</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">                 28.0383</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_2_AutoML_1_20240923_211230</td><td style=\"text-align: right;\">5.29513</td><td style=\"text-align: right;\">28.0384</td><td style=\"text-align: right;\">1.71412</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">                 28.0384</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_1_AutoML_1_20240923_211230   </td><td style=\"text-align: right;\">5.29523</td><td style=\"text-align: right;\">28.0395</td><td style=\"text-align: right;\">1.71372</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">                 28.0395</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_3_AutoML_1_20240923_211230   </td><td style=\"text-align: right;\">5.29554</td><td style=\"text-align: right;\">28.0428</td><td style=\"text-align: right;\">1.71425</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">                 28.0428</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_3_AutoML_1_20240923_211230</td><td style=\"text-align: right;\">5.29639</td><td style=\"text-align: right;\">28.0518</td><td style=\"text-align: right;\">1.71507</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">                 28.0518</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_1_20240923_211230                </td><td style=\"text-align: right;\">5.47443</td><td style=\"text-align: right;\">29.9694</td><td style=\"text-align: right;\">2.44844</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">                 29.9694</td></tr>\n",
       "<tr><td>DeepLearning_2_AutoML_2_20240924_61221                 </td><td style=\"text-align: right;\">5.61972</td><td style=\"text-align: right;\">31.5813</td><td style=\"text-align: right;\">2.68302</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">                 31.5813</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10 rows x 6 columns]</pre>"
      ],
      "text/plain": [
       "model_id                                                    rmse      mse      mae    rmsle    mean_residual_deviance\n",
       "-------------------------------------------------------  -------  -------  -------  -------  ------------------------\n",
       "GLM_2_AutoML_2_20240924_61221                            5.29464  28.0332  1.71254      nan                   28.0332\n",
       "GLM_1_AutoML_1_20240923_211230                           5.29464  28.0332  1.71254      nan                   28.0332\n",
       "StackedEnsemble_AllModels_2_AutoML_1_20240923_211230     5.29509  28.038   1.71367      nan                   28.038\n",
       "StackedEnsemble_BestOfFamily_1_AutoML_1_20240923_211230  5.29512  28.0383  1.71415      nan                   28.0383\n",
       "StackedEnsemble_BestOfFamily_2_AutoML_1_20240923_211230  5.29513  28.0384  1.71412      nan                   28.0384\n",
       "StackedEnsemble_AllModels_1_AutoML_1_20240923_211230     5.29523  28.0395  1.71372      nan                   28.0395\n",
       "StackedEnsemble_AllModels_3_AutoML_1_20240923_211230     5.29554  28.0428  1.71425      nan                   28.0428\n",
       "StackedEnsemble_BestOfFamily_3_AutoML_1_20240923_211230  5.29639  28.0518  1.71507      nan                   28.0518\n",
       "DeepLearning_1_AutoML_1_20240923_211230                  5.47443  29.9694  2.44844      nan                   29.9694\n",
       "DeepLearning_2_AutoML_2_20240924_61221                   5.61972  31.5813  2.68302      nan                   31.5813\n",
       "[10 rows x 6 columns]\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leaderboard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py310/lib/python3.10/site-packages/h2o/frame.py:1981: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model_id                  DeepLearning_1_AutoML_1_20240923_211230\n",
       "rmse                                                     5.474434\n",
       "mse                                                     29.969427\n",
       "mae                                                      2.448435\n",
       "rmsle                                                         NaN\n",
       "mean_residual_deviance                                  29.969427\n",
       "Name: 8, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leaderboard.as_data_frame().iloc[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepLearning_1_AutoML_1_20240923_211230\n",
      "Status of Neuron Layers: predicting target, regression, gaussian distribution, Quadratic loss, 3,101 weights/biases, 77.1 KB, 104,018 training samples, mini-batch size 1\n",
      "    layer    units    type       dropout    l1    l2    mean_rate               rate_rms                momentum    mean_weight             weight_rms           mean_bias             bias_rms\n",
      "--  -------  -------  ---------  ---------  ----  ----  ----------------------  ----------------------  ----------  ----------------------  -------------------  --------------------  -----------------------\n",
      "    1        286      Input      0.0\n",
      "    2        10       Rectifier  0.0        0.0   0.0   0.025230179532672037    0.009651198983192444    0.0         0.00023786274331370066  0.0954655110836029   0.7788656104215739    0.5845489501953125\n",
      "    3        10       Rectifier  0.0        0.0   0.0   0.008876945667725521    0.008416924625635147    0.0         -0.004443328110501171   0.28273701667785645  0.9809969561491746    0.06552445888519287\n",
      "    4        10       Rectifier  0.0        0.0   0.0   0.011014057626889553    0.023908764123916626    0.0         0.02570307268295437     0.3091564178466797   1.022937802614036     0.04745239019393921\n",
      "    5        1        Linear                0.0   0.0   0.00039743693923810497  0.00022761948639526963  0.0         0.034631247818470004    0.31644153594970703  0.017902538961798036  1.0971281125650402e-154\n",
      "{'default': 'Automatic', 'actual': 'Automatic', 'input': 'Automatic'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py310/lib/python3.10/site-packages/h2o/frame.py:1981: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    }
   ],
   "source": [
    "# Access a specific model by name\n",
    "model_id = aml.leaderboard.as_data_frame().iloc[8, 0]  # Extract the model ID as a string\n",
    "print(model_id)\n",
    "specific_model = h2o.get_model(model_id)\n",
    "\n",
    "# Get the neural network structure\n",
    "print(specific_model.summary())\n",
    "\n",
    "# Get the loss function\n",
    "print(specific_model.params['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status of Neuron Layers: predicting target, regression, gaussian distribution, Quadratic loss, 3,101 weights/biases, 77.1 KB, 104,018 training samples, mini-batch size 1\n",
      "    layer    units    type       dropout    l1    l2    mean_rate               rate_rms                momentum    mean_weight             weight_rms           mean_bias             bias_rms\n",
      "--  -------  -------  ---------  ---------  ----  ----  ----------------------  ----------------------  ----------  ----------------------  -------------------  --------------------  -----------------------\n",
      "    1        286      Input      0.0\n",
      "    2        10       Rectifier  0.0        0.0   0.0   0.025230179532672037    0.009651198983192444    0.0         0.00023786274331370066  0.0954655110836029   0.7788656104215739    0.5845489501953125\n",
      "    3        10       Rectifier  0.0        0.0   0.0   0.008876945667725521    0.008416924625635147    0.0         -0.004443328110501171   0.28273701667785645  0.9809969561491746    0.06552445888519287\n",
      "    4        10       Rectifier  0.0        0.0   0.0   0.011014057626889553    0.023908764123916626    0.0         0.02570307268295437     0.3091564178466797   1.022937802614036     0.04745239019393921\n",
      "    5        1        Linear                0.0   0.0   0.00039743693923810497  0.00022761948639526963  0.0         0.034631247818470004    0.31644153594970703  0.017902538961798036  1.0971281125650402e-154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py310/lib/python3.10/site-packages/h2o/frame.py:1981: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    }
   ],
   "source": [
    "# Access a specific model by name\n",
    "model_id = aml.leaderboard.as_data_frame().iloc[8, 0]  # Get the model ID\n",
    "specific_model = h2o.get_model(model_id)\n",
    "model = specific_model\n",
    "# Get model summary\n",
    "print(specific_model.summary())  # This will show details about the layers, units, activation functions, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model does not have weights and biases available for extraction.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a PyTorch model with the same architecture as the H2O model\n",
    "class ConvertedH2OModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ConvertedH2OModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the PyTorch model\n",
    "input_dim = num_features  # Assuming num_features is defined\n",
    "torch_model = ConvertedH2OModel(input_dim)\n",
    "\n",
    "# Check if the model has weights and biases\n",
    "if specific_model._model_json[\"output\"][\"weights\"] is not None and specific_model._model_json[\"output\"][\"biases\"] is not None:\n",
    "    # Extract weights and biases from the H2O model\n",
    "    h2o_weights = [specific_model.weights(i) for i in range(len(specific_model.params['hidden']))]\n",
    "    h2o_biases = [specific_model.biases(i) for i in range(len(specific_model.params['hidden']))]\n",
    "\n",
    "    # Assign the extracted weights and biases to the PyTorch model\n",
    "    with torch.no_grad():\n",
    "        torch_model.fc1.weight = nn.Parameter(torch.tensor(h2o_weights[0].T, dtype=torch.float32))\n",
    "        torch_model.fc1.bias = nn.Parameter(torch.tensor(h2o_biases[0], dtype=torch.float32))\n",
    "        torch_model.fc2.weight = nn.Parameter(torch.tensor(h2o_weights[1].T, dtype=torch.float32))\n",
    "        torch_model.fc2.bias = nn.Parameter(torch.tensor(h2o_biases[1], dtype=torch.float32))\n",
    "        torch_model.fc3.weight = nn.Parameter(torch.tensor(h2o_weights[2].T, dtype=torch.float32))\n",
    "        torch_model.fc3.bias = nn.Parameter(torch.tensor(h2o_biases[2], dtype=torch.float32))\n",
    "        torch_model.fc4.weight = nn.Parameter(torch.tensor(h2o_weights[3].T, dtype=torch.float32))\n",
    "        torch_model.fc4.bias = nn.Parameter(torch.tensor(h2o_biases[3], dtype=torch.float32))\n",
    "\n",
    "    # Now the torch_model is initialized with the weights and biases from the H2O model\n",
    "else:\n",
    "    print(\"The model does not have weights and biases available for extraction.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    " model._model_json[\"output\"][\"weights\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvertedH2OModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ConvertedH2OModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "        self.dropout = nn.Dropout(p=0.3)  # Adjust dropout based on your architecture\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the PyTorch model\n",
    "input_dim = 286  # Adjust based on your dataset\n",
    "torch_model = ConvertedH2OModel(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([10000])) that is different to the input size (torch.Size([10000, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 275.5254\n",
      "Epoch [20/100], Loss: 275.5214\n",
      "Epoch [30/100], Loss: 275.5193\n",
      "Epoch [40/100], Loss: 275.5181\n",
      "Epoch [50/100], Loss: 275.5172\n",
      "Epoch [60/100], Loss: 275.5167\n",
      "Epoch [70/100], Loss: 275.5163\n",
      "Epoch [80/100], Loss: 275.5161\n",
      "Epoch [90/100], Loss: 275.5158\n",
      "Epoch [100/100], Loss: 275.5157\n"
     ]
    }
   ],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(torch_model.parameters(), lr=0.001)\n",
    "\n",
    "# Example training loop (assuming X_train and y_train are your training data)\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = torch_model(X_tensor)\n",
    "    loss = criterion(outputs, y_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = h2o.get_model(model_id)\n",
    "if hasattr(model, 'metalearner'):\n",
    "    metalearner_params = model.metalearner().actual_params\n",
    "else:\n",
    "    metalearner_params = None\n",
    "se_params = model.actual_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm\n"
     ]
    }
   ],
   "source": [
    "print(aml.leader.algo)  # To check the type of algorithm (e.g., \"GBM\", \"DeepLearning\", etc.)# For deep learning models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_weights = aml.leader.coef(layer_number)\n",
    "# layer_biases = aml.leader.biases(layer_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Intercept': -0.05383154654340083,\n",
       " 'feature_0': 0.5272049781557735,\n",
       " 'feature_1': 0.21592772001764768,\n",
       " 'feature_2': 0.1540862842393204,\n",
       " 'feature_3': 0.07236426622464344,\n",
       " 'feature_4': -0.17708315292505578,\n",
       " 'feature_5': -0.5324016895714361,\n",
       " 'feature_6': -1.176444533475652,\n",
       " 'feature_7': 0.899782570976865,\n",
       " 'feature_8': 1.0532240069632302,\n",
       " 'feature_9': 1.173530299599555,\n",
       " 'feature_10': 1.8405155207005701,\n",
       " 'feature_11': -0.8727583211265966,\n",
       " 'feature_12': -1.8763701813875338,\n",
       " 'feature_13': 0.2540544724877997,\n",
       " 'feature_14': -1.66344180080521,\n",
       " 'feature_15': 0.4331708455484692,\n",
       " 'feature_16': -0.5358056313137141,\n",
       " 'feature_17': -1.8954152669536164,\n",
       " 'feature_18': -0.08352995719280579,\n",
       " 'feature_19': 0.36538576313052973,\n",
       " 'feature_20': 1.3202206727795143,\n",
       " 'feature_21': 0.5991797451939189,\n",
       " 'feature_22': 0.7828946605091546,\n",
       " 'feature_23': -1.4058715506475654,\n",
       " 'feature_24': -0.15409528486836158,\n",
       " 'feature_25': -0.938312481036799,\n",
       " 'feature_26': -1.5940512677919938,\n",
       " 'feature_27': -2.110544037512941,\n",
       " 'feature_28': 0.2665463013908728,\n",
       " 'feature_29': 0.8337188176705237,\n",
       " 'feature_30': 0.5307652080886068,\n",
       " 'feature_31': 1.4714232544379717,\n",
       " 'feature_32': 0.5543445728016817,\n",
       " 'feature_33': 0.04736273778703407,\n",
       " 'feature_34': 2.311906495864378,\n",
       " 'feature_35': 0.2739703381000988,\n",
       " 'feature_36': -1.5992722029678064,\n",
       " 'feature_37': -1.1142151450539646,\n",
       " 'feature_38': 0.40323634023256355,\n",
       " 'feature_39': -0.672648049910055,\n",
       " 'feature_40': -0.21522641313198096,\n",
       " 'feature_41': 1.0326075892453266,\n",
       " 'feature_42': -1.075148253770562,\n",
       " 'feature_43': -1.4876555529160465,\n",
       " 'feature_44': 0.5244641190106435,\n",
       " 'feature_45': -0.6866400438337744,\n",
       " 'feature_46': -1.2296566170411332,\n",
       " 'feature_47': 0.2658073533801616,\n",
       " 'feature_48': -0.39202448115228106,\n",
       " 'feature_49': 0.14859179271661738,\n",
       " 'feature_50': 0.2598304033657298,\n",
       " 'feature_51': 1.5184465517395405,\n",
       " 'feature_52': 0.8605052343480817,\n",
       " 'feature_53': 0.0848096277573231,\n",
       " 'feature_54': -1.016647434474352,\n",
       " 'feature_55': 0.6845653674175384,\n",
       " 'feature_56': -0.742075419652894,\n",
       " 'feature_57': 0.38557941954026304,\n",
       " 'feature_58': 0.5302178460969257,\n",
       " 'feature_59': 0.7502779161454926,\n",
       " 'feature_60': -1.314627031751813,\n",
       " 'feature_61': -1.182393567074097,\n",
       " 'feature_62': -2.121510495548577,\n",
       " 'feature_63': -1.0030325422740445,\n",
       " 'feature_64': -0.9487882256654941,\n",
       " 'feature_65': -1.3006503892441155,\n",
       " 'feature_66': -0.15442201738769123,\n",
       " 'feature_67': -0.6856748423179057,\n",
       " 'feature_68': 1.1336937383460393,\n",
       " 'feature_69': 0.16360183221111657,\n",
       " 'feature_70': 1.305626021606641,\n",
       " 'feature_71': -1.0587835031330413,\n",
       " 'feature_72': 0.5445933758968429,\n",
       " 'feature_73': 1.2801272821822198,\n",
       " 'feature_74': -0.8498008494962215,\n",
       " 'feature_75': -1.3392460906975454,\n",
       " 'feature_76': 0.10340996068941158,\n",
       " 'feature_77': 1.2053330503052915,\n",
       " 'feature_78': -1.2161965856612764,\n",
       " 'feature_79': 1.6324619208472102,\n",
       " 'feature_80': -0.003196346564383095,\n",
       " 'feature_81': 0.13717892322427086,\n",
       " 'feature_82': -1.4906993776101762,\n",
       " 'feature_83': -0.22420976695838982,\n",
       " 'feature_84': 0.696547694745666,\n",
       " 'feature_85': 0.0280673182129964,\n",
       " 'feature_86': 0.23169649586147256,\n",
       " 'feature_87': -0.0895984939772682,\n",
       " 'feature_88': 1.5003083717847978,\n",
       " 'feature_89': -0.7875916286303879,\n",
       " 'feature_90': -0.8058834541522993,\n",
       " 'feature_91': -1.4143010449757534,\n",
       " 'feature_92': 0.6061067267039968,\n",
       " 'feature_93': -0.34709705727578793,\n",
       " 'feature_94': 0.42776086814959746,\n",
       " 'feature_95': 0.0439804547515894,\n",
       " 'feature_96': -1.4056036246570076,\n",
       " 'feature_97': -1.4053788658788597,\n",
       " 'feature_98': -1.2132993924165614,\n",
       " 'feature_99': 1.2898817135353233,\n",
       " 'feature_100': -2.1622350085529374,\n",
       " 'feature_101': 0.5575831301409487,\n",
       " 'feature_102': 0.4944402050810809,\n",
       " 'feature_103': -1.0482555066494534,\n",
       " 'feature_104': 0.787080708068021,\n",
       " 'feature_105': 0.5597648731836401,\n",
       " 'feature_106': -0.8584138304333759,\n",
       " 'feature_107': 0.9031070152563797,\n",
       " 'feature_108': -0.16914974941377847,\n",
       " 'feature_109': -0.4651221141317035,\n",
       " 'feature_110': 0.4655909738321988,\n",
       " 'feature_111': -1.8368979219206776,\n",
       " 'feature_112': 0.06553757127842155,\n",
       " 'feature_113': -1.1805929874471266,\n",
       " 'feature_114': -1.2554750947982616,\n",
       " 'feature_115': 0.7973485138735521,\n",
       " 'feature_116': -1.246272031049467,\n",
       " 'feature_117': -0.8895213677848398,\n",
       " 'feature_118': 0.9437949924280504,\n",
       " 'feature_119': 0.025094622361882483,\n",
       " 'feature_120': -0.43739123760072707,\n",
       " 'feature_121': 0.24734615663299572,\n",
       " 'feature_122': -0.2122868966404791,\n",
       " 'feature_123': 1.0529980973917359,\n",
       " 'feature_124': -0.7432106796483166,\n",
       " 'feature_125': -0.012264246126886017,\n",
       " 'feature_126': 1.232534952120906,\n",
       " 'feature_127': -0.9762587897660199,\n",
       " 'feature_128': -0.8797958184384376,\n",
       " 'feature_129': 1.3393548521706558,\n",
       " 'feature_130': -0.197780775387403,\n",
       " 'feature_131': 0.14715383067605306,\n",
       " 'feature_132': -0.6413934541656509,\n",
       " 'feature_133': -1.6242113333521124,\n",
       " 'feature_134': 1.442267791035894,\n",
       " 'feature_135': -1.4549928659669673,\n",
       " 'feature_136': -1.767625473835306,\n",
       " 'feature_137': -0.876519086029007,\n",
       " 'feature_138': 0.24261897274359778,\n",
       " 'feature_139': 0.08677137319142347,\n",
       " 'feature_140': 1.0297474982896568,\n",
       " 'feature_141': -0.6159428024371713,\n",
       " 'feature_142': -0.9731584677245702,\n",
       " 'feature_143': 1.75763926322588,\n",
       " 'feature_144': 0.12075792131655395,\n",
       " 'feature_145': 0.8032113872357928,\n",
       " 'feature_146': -0.4421993726588213,\n",
       " 'feature_147': 0.09621012553989974,\n",
       " 'feature_148': 0.5831224534918175,\n",
       " 'feature_149': 0.17794603048578714,\n",
       " 'feature_150': -0.5788473719389609,\n",
       " 'feature_151': 0.5126836174966614,\n",
       " 'feature_152': -0.579992028892304,\n",
       " 'feature_153': -1.8394428810291745,\n",
       " 'feature_154': 1.5634876643062834,\n",
       " 'feature_155': -0.14537782859919748,\n",
       " 'feature_156': 1.4834326625529777,\n",
       " 'feature_157': -0.6725248882563787,\n",
       " 'feature_158': -1.1155458691895959,\n",
       " 'feature_159': 0.366345733564399,\n",
       " 'feature_160': 1.4867153504793311,\n",
       " 'feature_161': -2.1524346834463275,\n",
       " 'feature_162': 0.4866922003870974,\n",
       " 'feature_163': 0.9245294048200136,\n",
       " 'feature_164': -0.24129336889264266,\n",
       " 'feature_165': -0.27252835407172094,\n",
       " 'feature_166': 0.2827990554093717,\n",
       " 'feature_167': -0.5111855498911746,\n",
       " 'feature_168': -0.1462642212983978,\n",
       " 'feature_169': -1.7213863067334685,\n",
       " 'feature_170': 0.808990469293468,\n",
       " 'feature_171': 1.9986998927007746,\n",
       " 'feature_172': 1.7525206611308268,\n",
       " 'feature_173': 0.43094166505349835,\n",
       " 'feature_174': 0.43008598372471185,\n",
       " 'feature_175': -0.7629727051438885,\n",
       " 'feature_176': -0.5406068942887589,\n",
       " 'feature_177': -0.9386854329738427,\n",
       " 'feature_178': -0.5150622491159877,\n",
       " 'feature_179': -0.7291765869439762,\n",
       " 'feature_180': 0.9993036780611556,\n",
       " 'feature_181': 1.564368216482111,\n",
       " 'feature_182': 2.1979788149012274,\n",
       " 'feature_183': -0.538941628904816,\n",
       " 'feature_184': -0.6868961486178108,\n",
       " 'feature_185': -2.0759550272692433,\n",
       " 'feature_186': -1.153865624629687,\n",
       " 'feature_187': 3.5633898872541856,\n",
       " 'feature_188': -0.838084492443243,\n",
       " 'feature_189': 0.5001300402420668,\n",
       " 'feature_190': 0.5124031228397279,\n",
       " 'feature_191': 1.6145115477510397,\n",
       " 'feature_192': 0.1868816713704118,\n",
       " 'feature_193': 0.353095379974284,\n",
       " 'feature_194': -0.035017651407132505,\n",
       " 'feature_195': 0.18504817757996486,\n",
       " 'feature_196': 0.32937372005236515,\n",
       " 'feature_197': 1.5216540496516324,\n",
       " 'feature_198': -0.1065587740804209,\n",
       " 'feature_199': 0.23277934312682944,\n",
       " 'feature_200': 0.13028034179431078,\n",
       " 'feature_201': 0.7708463029121324,\n",
       " 'feature_202': 1.017888988820854,\n",
       " 'feature_203': -1.3383863510765914,\n",
       " 'feature_204': -0.7139033829463212,\n",
       " 'feature_205': 0.3293981469791043,\n",
       " 'feature_206': -0.05042774658962641,\n",
       " 'feature_207': -0.8106279567181692,\n",
       " 'feature_208': 0.21260467644618264,\n",
       " 'feature_209': -0.9182209524873479,\n",
       " 'feature_210': -0.6801705967616369,\n",
       " 'feature_211': -2.3352240234957877,\n",
       " 'feature_212': 0.6468861480158974,\n",
       " 'feature_213': -0.3682388882634895,\n",
       " 'feature_214': -0.7475073922572909,\n",
       " 'feature_215': -0.6471713446666502,\n",
       " 'feature_216': 0.5713977460517025,\n",
       " 'feature_217': 0.23319399282421507,\n",
       " 'feature_218': -0.6798175853693886,\n",
       " 'feature_219': 1.3583142592147042,\n",
       " 'feature_220': -1.1149350602537689,\n",
       " 'feature_221': 0.15597116024613616,\n",
       " 'feature_222': 0.8845858903684561,\n",
       " 'feature_223': -1.7628468966524196,\n",
       " 'feature_224': 1.9487441246545343,\n",
       " 'feature_225': 0.1738968590967657,\n",
       " 'feature_226': -0.11674892682506349,\n",
       " 'feature_227': 0.8296460535685329,\n",
       " 'feature_228': 0.08779736666293478,\n",
       " 'feature_229': -0.7990445571831157,\n",
       " 'feature_230': -1.0354360649341647,\n",
       " 'feature_231': -0.2293844719857678,\n",
       " 'feature_232': 1.501342503099074,\n",
       " 'feature_233': -0.1671253056414743,\n",
       " 'feature_234': -0.5537364024732742,\n",
       " 'feature_235': 0.5120826453618562,\n",
       " 'feature_236': 0.26079664265216307,\n",
       " 'feature_237': -0.49567428633047594,\n",
       " 'feature_238': -0.19135336371302536,\n",
       " 'feature_239': -0.2283534243011993,\n",
       " 'feature_240': -0.9545215540298869,\n",
       " 'feature_241': 0.07952720561574013,\n",
       " 'feature_242': 0.5350372861814715,\n",
       " 'feature_243': 0.5414431645118082,\n",
       " 'feature_244': 0.32929110854646465,\n",
       " 'feature_245': -2.260711678850617,\n",
       " 'feature_246': 0.39837125135157636,\n",
       " 'feature_247': -0.007678304280638086,\n",
       " 'feature_248': -0.11497337040509988,\n",
       " 'feature_249': 0.3434399476966387,\n",
       " 'feature_250': 0.8242981144358126,\n",
       " 'feature_251': 1.0276147047030415,\n",
       " 'feature_252': 0.8045778265220506,\n",
       " 'feature_253': 1.1814308963117326,\n",
       " 'feature_254': 0.7600820918685824,\n",
       " 'feature_255': -0.6278245586330958,\n",
       " 'feature_256': 0.6558749293311577,\n",
       " 'feature_257': 2.166255323579164,\n",
       " 'feature_258': 0.3247640224856476,\n",
       " 'feature_259': -0.8664044588990237,\n",
       " 'feature_260': -0.03698661724771621,\n",
       " 'feature_261': -0.614261359889858,\n",
       " 'feature_262': -0.2982367528124573,\n",
       " 'feature_263': 1.1646764320727838,\n",
       " 'feature_264': 0.9213192993328855,\n",
       " 'feature_265': 0.5959576891753556,\n",
       " 'feature_266': 0.22887761792088268,\n",
       " 'feature_267': -1.234302936778869,\n",
       " 'feature_268': -0.9167109029886095,\n",
       " 'feature_269': 1.223989594580785,\n",
       " 'feature_270': -0.491974420520363,\n",
       " 'feature_271': 0.851458414957684,\n",
       " 'feature_272': 0.2539828209420497,\n",
       " 'feature_273': 0.2280132557896768,\n",
       " 'feature_274': -1.4152149104872986,\n",
       " 'feature_275': -1.669314046707641,\n",
       " 'feature_276': -1.783384656076283,\n",
       " 'feature_277': -0.3560649406743155,\n",
       " 'feature_278': 0.009931968611819051,\n",
       " 'feature_279': -1.247065677138049,\n",
       " 'feature_280': 0.46774820988451765,\n",
       " 'feature_281': -0.07783751051918136,\n",
       " 'feature_282': 0.2909956899549811,\n",
       " 'feature_283': -0.46979992793065606,\n",
       " 'feature_284': -0.9049481899576874,\n",
       " 'feature_285': 0.6575415153958142}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader.coef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'biases'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43maml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbiases\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py310/lib/python3.10/site-packages/h2o/model/model_base.py:439\u001b[0m, in \u001b[0;36mModelBase.biases\u001b[0;34m(self, vector_id)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbiases\u001b[39m(\u001b[38;5;28mself\u001b[39m, vector_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    432\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03m    Return the frame for the respective bias vector.\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m    :returns: an H2OFrame which represents the bias vector identified by ``vector_id``.\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 439\u001b[0m     num_bias_vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_json\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbiases\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m vector_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(num_bias_vectors)):\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    442\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBias vector does not exist. Model has \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m bias vectors (0-based indexing), but vector \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    443\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwas requested.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(num_bias_vectors, vector_id))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'biases'"
     ]
    }
   ],
   "source": [
    "aml.leader.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
